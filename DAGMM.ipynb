{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7e46eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc21703",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DAGMM(nn.Module):\n",
    "\n",
    "    def __init__(self, enc_dims, estim_dims, types):\n",
    "        super(DAGMM,self).__init__()\n",
    "\n",
    "        self.encoder, self.decoder = self.construct_ae(enc_dims)\n",
    "        self.estim_net = self.construct_estim_net(estim_dims, types)\n",
    "\n",
    "    def construct_ae(self, dimensions):\n",
    "        enc_layers = []\n",
    "        n_dims = len(dimensions)\n",
    "        for i in range(n_dims):\n",
    "            enc_layers.append(nn.Linear(dimensions[i][0], dimensions[i][1]))\n",
    "            if i < n_dims-1:\n",
    "                enc_layers.append(nn.Tanh())\n",
    "\n",
    "        rev_dims = dimensions[::-1]\n",
    "        dec_layers = []\n",
    "        for i in range(n_dims):\n",
    "            dec_layers.append(nn.Linear(rev_dims[i][1], rev_dims[i][0]))\n",
    "            if i < n_dims-1:\n",
    "                dec_layers.append(nn.Tanh())\n",
    "\n",
    "        return nn.Sequential(*enc_layers), nn.Sequential( *dec_layers)\n",
    "    \n",
    "    def construct_estim_net(self, dimensions, types):\n",
    "        layers = []\n",
    "        n_dims = len(dimensions)\n",
    "        for i in range(n_dims):\n",
    "            if types[i] == 'Linear':\n",
    "                if i == 0:\n",
    "                    layers.append(nn.Linear(dimensions[i][0] + 2, dimensions[i][1]))\n",
    "                else:\n",
    "                    layers.append(nn.Linear(dimensions[i][0], dimensions[i][1]))\n",
    "                if i < n_dims-1:\n",
    "                    layers.append(nn.Tanh())\n",
    "                else:\n",
    "                    layers.append(nn.Softmax(dim = -1))\n",
    "            if types[i] == 'drop':\n",
    "                layers.append(nn.Dropout(p=dimensions[i]))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def compute_gmm_params(self, z, gamma):\n",
    "        N = gamma.size(0)\n",
    "        sum_gamma = torch.sum(gamma, dim=0)\n",
    "\n",
    "        # Phy reppresent the importance of the components\n",
    "        self.phi = (sum_gamma / N).detach() # K\n",
    "\n",
    "        # Mu are the expected values of the mixture\n",
    "        self.mu = (torch.sum(gamma.unsqueeze(-1)*z.unsqueeze(1), dim=0) / sum_gamma.unsqueeze(1)).detach() # K x D\n",
    "\n",
    "        # Sigma are the covariance matrixes of the mixture\n",
    "        z_mu = z.unsqueeze(1) - self.mu.unsqueeze(0) # N x K x D\n",
    "\n",
    "        z_outer = z_mu.unsqueeze(-1) * z_mu.unsqueeze(-2) # N x K x D x D\n",
    "\n",
    "        self.cov = (torch.sum(gamma.unsqueeze(-1).unsqueeze(-1) * z_outer, dim=0) / sum_gamma.unsqueeze(-1).unsqueeze(-1)).detach() # K x D x D\n",
    "\n",
    "    def compute_energy(self, z, flag=True):\n",
    "\n",
    "        z_mu = z.unsqueeze(1) - self.mu.unsqueeze(0) # N x K x D\n",
    "\n",
    "        # Inverse matrix \n",
    "        eps = 1e-12 # Done for numerical errors\n",
    "        eye = torch.eye(self.cov.size(-1)).to(self.cov.device)\n",
    "        cov_reg = self.cov + (eye * eps)\n",
    "        if flag:\n",
    "            self.cov_inverse = torch.linalg.inv(cov_reg) # K x D x D\n",
    "\n",
    "        # Log determnant calculation for numerical stability\n",
    "        log_det = 0.5 * torch.linalg.slogdet(2 * torch.pi * cov_reg)[1]\n",
    "\n",
    "        # Exponential term autonormalized for stability\n",
    "        malan = -0.5 * torch.sum(torch.sum(z_mu.unsqueeze(-1) * self.cov_inverse.unsqueeze(0), dim=-2) * z_mu, dim=-1)\n",
    "        exponent = torch.log(self.phi + eps).unsqueeze(0) + malan - log_det.unsqueeze(0) # K\n",
    "        max_val = torch.max(exponent, dim=1, keepdim=True)[0]\n",
    "        exp_term = torch.exp(exponent - max_val)\n",
    "\n",
    "        energy = - (max_val.squeeze() + torch.log(torch.sum(exp_term, dim=1) + eps))\n",
    "\n",
    "        # Computing the regularization penality for loss\n",
    "        diagonals = torch.diagonal(cov_reg, dim1=-2, dim2=-1)\n",
    "        p_sigma = torch.sum(1.0 / (diagonals + eps))\n",
    "\n",
    "        if flag:\n",
    "            return torch.mean(energy), p_sigma\n",
    "        else:\n",
    "            return energy, p_sigma\n",
    "\n",
    "    def con_loss(self, x, x_rec, z, gamma, lam_energy, lam_cov):\n",
    "        rec_err = torch.mean((x-x_rec)**2)\n",
    "\n",
    "        self.compute_gmm_params(z, gamma)\n",
    "\n",
    "        energy, p_sigma = self.compute_energy(z)\n",
    "        \n",
    "        return rec_err + lam_energy * energy + lam_cov * p_sigma\n",
    "\n",
    "    def get_estimation_input(self, x, x_rec, z_c):\n",
    "        # Compute the inpute vector to the estimation net\n",
    "        # Euclidean dist\n",
    "        euclidean_dist = torch.norm(x - x_rec, p=2, dim=1, keepdim=True) / torch.norm(x, p=2, dim=1, keepdim=True)\n",
    "        \n",
    "        # Cosine Similarity\n",
    "        cosine_sim = nn.functional.cosine_similarity(x, x_rec, dim=1).unsqueeze(1)\n",
    "        \n",
    "        z_combined = torch.cat([z_c, euclidean_dist, cosine_sim], dim=1)\n",
    "        return z_combined\n",
    "\n",
    "    def predict(self, x):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            z = self.encoder(x)\n",
    "            x_rec = self.decoder(z)\n",
    "            est_in = self.get_estimation_input(x, x_rec, z)\n",
    "\n",
    "        return self.compute_energy(est_in, False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
